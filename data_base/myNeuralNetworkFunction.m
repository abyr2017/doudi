function [y1] = myNeuralNetworkFunction(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 13-Aug-2017 13:39:00.
% 
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = 2xQ matrix, input #1
% and returns:
%   y = 4xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [-0.392732717567874;-0.389840038768807];
x1_step1.gain = [1.11602140113636;1.12719358184917];
x1_step1.ymin = -1;

% Layer 1
b1 = [4.2630529033741409;-2.8325697244584105;-1.9447633600940795;-1.7032539503405377;-0.15961283626616929;-0.14045293322299074;-0.36640334047832956;-1.9350972459993534;2.5883627327469592;-3.6207411463134296];
IW1_1 = [-3.7883198468870019 -2.5107061768014205;4.0077141562786851 -2.4940343323838241;3.4845798261849072 -3.4952812901797903;3.6478867602336842 -2.9905831861916816;-0.36624966432867379 -7.2281813349026303;-6.358841513690134 -0.2409643370291685;-5.5067092705012008 0.76163727282546789;-3.7770000016664609 3.7375454292305408;3.8156161285223629 -3.0054410058857006;-0.58894905469470737 4.9860485966115675];

% Layer 2
b2 = [-0.98379558159991964;-0.51037608727682138;-0.28320020749134245;-0.31406602679765416];
LW2_1 = [-0.58445300458950311 -0.82223891811506566 -0.86171304874408372 -1.7755368246210992 5.6528795469759663 4.3958647038146363 0.66480313300017713 -0.49020936890522793 -0.14343073640519197 -0.44274611448607959;0.77974588487597851 0.2466220761636129 -0.40292087824671552 -0.64985786628432363 -5.5451657675603112 2.9748356360859023 2.899592588968257 3.1177374643000202 -0.85153070740892889 -0.663670227595476;0.70116465068585898 0.6462014853228738 2.1288332751109955 2.0486284997819442 4.4629514601701068 -4.0433470547976089 -1.5161609217370133 0.1687778921156359 0.23887755657181575 -0.46860214395634564;-0.44246862171352402 0.5342216920938484 -0.94709575174761018 -0.9501319832049715 -5.7327322476589666 -3.9873757828949969 -2.0029125608058931 -1.5608234417412417 1.3153494928521476 1.1559870444766656];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = [2;2;2;2];
y1_step1.xoffset = [0;0;0;0];

% ===== SIMULATION ========

% Dimensions
Q = size(x1,2); % samples

% Input 1
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);

% Output 1
y1 = mapminmax_reverse(a2,y1_step1);
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
  y = bsxfun(@minus,x,settings.xoffset);
  y = bsxfun(@times,y,settings.gain);
  y = bsxfun(@plus,y,settings.ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
  if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
  else
    a = iSoftmaxApplyCPU(n);
  end
end
function a = iSoftmaxApplyCPU(n)
  nmax = max(n,[],1);
  n = bsxfun(@minus,n,nmax);
  numerator = exp(n);
  denominator = sum(numerator,1); 
  denominator(denominator == 0) = 1;
  a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
  nmax = max(n,[],1);
  numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
  denominator = sum(numerator,1);
  a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
  numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
  if (denominator == 0)
    a = numerator;
  else
    a = numerator ./ denominator;
  end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
  x = bsxfun(@minus,y,settings.ymin);
  x = bsxfun(@rdivide,x,settings.gain);
  x = bsxfun(@plus,x,settings.xoffset);
end
